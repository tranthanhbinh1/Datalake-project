{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/21 22:12:45 WARN Utils: Your hostname, Legion resolves to a loopback address: 127.0.1.1; using 172.21.29.24 instead (on interface eth0)\n",
      "23/06/21 22:12:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/21 22:12:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/06/21 22:12:46 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "23/06/21 22:12:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName(\"nyc_taxi\").config(\"spark.local.dir\", \"/home/tb24/projects/Datalake-project\").getOrCreate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/home/tb24/projects/Datalake-project/data/yellow_tripdata_2023-03.parquet\")\n",
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df.createOrReplaceGlobalTempView(\"dfTable\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "| avg(total_amount)|\n",
      "+------------------+\n",
      "|27.803426281277332|\n",
      "+------------------+\n",
      "\n",
      "+------------------+\n",
      "|avg(trip_distance)|\n",
      "+------------------+\n",
      "| 3.903870542216571|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:====================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+-----------------+----------------------------+\n",
      "|average_tip_amount|average_toll_amount|     average_fare|average_congestion_surcharge|\n",
      "+------------------+-------------------+-----------------+----------------------------+\n",
      "|3.4952374575695115| 0.5670058928868822|18.90844797498149|           2.275175678279642|\n",
      "+------------------+-------------------+-----------------+----------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "# Average fee of a taxi ride\n",
    "df.selectExpr(\"avg(total_amount)\").show(2)\n",
    "# Average trip Distance\n",
    "df.select(avg(\"trip_distance\")).show(2)\n",
    "# Average tips, tolls and fare and congestion surcharge\n",
    "df.select(avg(\"tip_amount\").alias(\"average_tip_amount\"),\n",
    "          avg(\"tolls_amount\").alias('average_toll_amount'),\n",
    "          avg(\"fare_amount\").alias('average_fare'),\n",
    "          avg(\"congestion_surcharge\").alias('average_congestion_surcharge')\n",
    ").show(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|max(passenger_count)|\n",
      "+--------------------+\n",
      "|                   9|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|trip_distance|max(fare_amount)|\n",
      "+-------------+----------------+\n",
      "|         9.13|            70.0|\n",
      "|         14.9|           118.2|\n",
      "+-------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max, count_distinct, col\n",
    "# Biggest number of Passengers\n",
    "df.select(max('passenger_count')).show(2)\n",
    "# Biggest fare for a ride and its trip distance\n",
    "df.groupby('trip_distance').agg(max('fare_amount')).show(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|trip_distance|\n",
      "+-------------+\n",
      "|    216986.96|\n",
      "|    157733.41|\n",
      "|    144561.23|\n",
      "|    103942.41|\n",
      "|      70457.9|\n",
      "+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------------+\n",
      "|max(trip_distance)|\n",
      "+------------------+\n",
      "|         216986.96|\n",
      "+------------------+\n",
      "\n",
      "+------------+-------------+------------------+\n",
      "|total_amount|trip_distance|Store_and_fwd_flag|\n",
      "+------------+-------------+------------------+\n",
      "|       39.25|    216986.96|              null|\n",
      "+------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc, asc, expr\n",
    "df.select(col(\"trip_distance\")).orderBy(col(\"trip_distance\").desc()).show(5)\n",
    "df.select(max(\"trip_distance\")).show(1)\n",
    "\n",
    "# Outlier - big miles small prices what the hell\n",
    "df.select(col('total_amount'), col('trip_distance'), col('Store_and_fwd_flag'))\\\n",
    "    .where(col('trip_distance') == 216986.96).show(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
